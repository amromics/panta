{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def contingency_matrix(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Computes the contingency matrix between true and predicted labels.\n",
    "    \n",
    "    Parameters:\n",
    "    true_labels : list or numpy array\n",
    "        True cluster labels of the data points.\n",
    "    predicted_labels : list or numpy array\n",
    "        Predicted cluster labels of the data points.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray\n",
    "        Contingency matrix (n_clusters_true x n_clusters_pred).\n",
    "    \"\"\"\n",
    "    n_classes = len(np.unique(true_labels))\n",
    "    n_clusters = len(np.unique(predicted_labels))\n",
    "    contingency = np.zeros((n_classes, n_clusters), dtype=np.int64)\n",
    "    \n",
    "    for i in range(len(true_labels)):\n",
    "        contingency[true_labels[i], predicted_labels[i]] += 1\n",
    "    \n",
    "    return contingency\n",
    "\n",
    "def calculate_adjusted_rand_index(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Calculates the Adjusted Rand Index (ARI) between true and predicted cluster labels.\n",
    "    \n",
    "    Parameters:\n",
    "    true_labels : list or numpy array\n",
    "        True cluster labels of the data points.\n",
    "    predicted_labels : list or numpy array\n",
    "        Predicted cluster labels of the data points.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Adjusted Rand Index between true and predicted cluster labels.\n",
    "    \"\"\"\n",
    "    contingency = contingency_matrix(true_labels, predicted_labels)\n",
    "    n_samples = len(true_labels)\n",
    "    \n",
    "    # Calculate the ARI using the contingency matrix\n",
    "    a_i = np.sum(contingency, axis=1)\n",
    "    b_j = np.sum(contingency, axis=0)\n",
    "    \n",
    "    # Calculate the terms needed for ARI\n",
    "    sum_combinations = np.sum(comb2(a_i))  # sum of C(a_i, 2) for all clusters i\n",
    "    sum_combinations_prime = np.sum(comb2(b_j))  # sum of C(b_j, 2) for all clusters j\n",
    "    sum_combinations_squared = np.sum(comb2(contingency.flatten()))  # sum of C(n_ij, 2) for all pairs (i, j)\n",
    "    total_combinations = comb2(n_samples)\n",
    "    \n",
    "    # Expected index\n",
    "    expected_index = (sum_combinations * sum_combinations_prime) / total_combinations\n",
    "    max_index = (sum_combinations + sum_combinations_prime) / 2\n",
    "    \n",
    "    # Adjusted Rand Index\n",
    "    if max_index == expected_index:\n",
    "        ARI = 0.0\n",
    "    else:\n",
    "        ARI = (sum_combinations_squared - expected_index) / (max_index - expected_index)\n",
    "    \n",
    "    return ARI\n",
    "\n",
    "def comb2(n):\n",
    "    \"\"\"\n",
    "    Calculate the number of combinations C(n, 2).\n",
    "    \n",
    "    Parameters:\n",
    "    n : int\n",
    "        Number to calculate combinations for.\n",
    "    \n",
    "    Returns:\n",
    "    int\n",
    "        Combinations C(n, 2).\n",
    "    \"\"\"\n",
    "    return n * (n - 1) // 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cluster\n",
    "import json\n",
    "def loadClusterFromFile(filepath):\n",
    "    map_cluster={}\n",
    "    f = open(filepath)\n",
    "    data = json.load(f)\n",
    "    c_id=0\n",
    "    gene_set =  set()\n",
    "    for i in data.keys():\n",
    "        #print(i)\n",
    "        for gene in data[i]['gene_id']:\n",
    "            #print(gene)\n",
    "            map_cluster[gene]=c_id\n",
    "            gene_set.add(gene)\n",
    "        c_id=c_id+1\n",
    "    print(str(len(gene_set))+\" seq, \"+str(c_id)+\" cluster\")\n",
    "    list_gene=list(gene_set)\n",
    "    list_gene.sort()\n",
    "    \n",
    "    arr=[]\n",
    "    for i in range(len(list_gene)):\n",
    "        arr.append(map_cluster[list_gene[i]])\n",
    "    return arr\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194625 seq, 7633 cluster\n",
      "1194625 seq, 27044 cluster\n",
      "1194625 seq, 7366 cluster\n",
      "1194625 seq, 9443 cluster\n",
      "1194625 seq, 16782 cluster\n"
     ]
    }
   ],
   "source": [
    "g_cdhit_a_diamond_c_mcl=loadClusterFromFile('/mnt/data/data/amromics/panta2/panta/out/Sp600/g_cdhit_a_diamond_c_mcl/annotated_clusters.json')\n",
    "g_diamond_a_diamond_c_mcl=loadClusterFromFile('/mnt/data/data/amromics/panta2/panta/out/Sp600/g_diamond_a_diamond_c_mcl/annotated_clusters.json')\n",
    "g_mmseq_a_diamond_c_mcl=loadClusterFromFile('/mnt/data/data/amromics/panta2/panta/out/Sp600/g_mmseq_a_diamond_c_mcl/annotated_clusters.json')\n",
    "c_mmseq=loadClusterFromFile('/mnt/data/data/amromics/panta2/panta/out/Sp600/c_mmseq/annotated_clusters.json')\n",
    "c_diamond=loadClusterFromFile('/mnt/data/data/amromics/panta2/panta/out/Sp600/c_diamond/annotated_clusters.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7890185563290272"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_adjusted_rand_index(g_cdhit_a_diamond_c_mcl,g_diamond_a_diamond_c_mcl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9951394757083515"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_adjusted_rand_index(g_cdhit_a_diamond_c_mcl,g_mmseq_a_diamond_c_mcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844329097212963"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_adjusted_rand_index(g_cdhit_a_diamond_c_mcl,c_mmseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260373926710616"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_adjusted_rand_index(g_cdhit_a_diamond_c_mcl,c_diamond)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
